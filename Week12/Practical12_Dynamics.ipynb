{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Practical 12: Articulated Robots - Dynamics Part 2</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib notebook\n",
    "\n",
    "import roboticstoolbox as rtb\n",
    "from roboticstoolbox import DHRobot, RevoluteDH\n",
    "from spatialmath import SE3, SO3\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "sys.path.insert(0, os.path.abspath('Support'))\n",
    "\n",
    "from visualizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamics 3-dof Manipulator\n",
    "\n",
    "Recall the 3-dof manipulator we saw in the last lecture\n",
    "\n",
    "<img src=\"Support/images/3dof-linkrobot2.png\" width=\"400\" height=\"400\" align=\"center\">\n",
    "\n",
    "\n",
    "This manipulator consists of 3 revolute joints with attributes\n",
    "\n",
    "|$\\theta_j$\t| $d_j$ |   $a_j$\t|  $\\alpha_j$|\n",
    "|---\t|---\t|---\t|---\t|\n",
    "| $q_1$\t|  1\t|  0\t|  $\\frac{\\pi}{2}$ |\n",
    "| $q_2$ |  0 \t|  1\t| None \t|\n",
    "| $q_3$ |  0\t|  1\t| None\t|\n",
    "\n",
    "where $d_j$ is the link offset, $a_j$ is the link length and $\\alpha_j$ corresponds to the link twist\n",
    "\n",
    "We extend the definition of each link and include the rigid-body inertial parameters, and motor and transmission parameters. These parameters are:\n",
    "-  ``m``: link mass\n",
    "- ``r``: position of center of mass (COM) with respect to link frame\n",
    "- ``I``: inertia of link with respect to COM\n",
    "- ``Jm``: motor inertia\n",
    "- ``B``: motor viscous friction\n",
    "- ``G``: gear ratio\n",
    "\n",
    "<p style=\"color:#0000FF\";> <b>Note: If you want to know what a function does, just click somewhere within the parentheses that enclose the arguments and hit SHIFT+TAB. If there's a + button at the top of the popup tooltip, this means the documentation spans a few lines, click it to show the full docstring, then scroll up.</b></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Robot Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = RevoluteDH(d=1.0, a=0, alpha=np.pi/2, m=0, qlim=[-2.8, 2.8],\n",
    "                  r=np.zeros(3), Jm=200e-6, G=60, B=1.38e-3,\n",
    "                  I=[0, 0.35, 0, 0, 0, 0])\n",
    "\n",
    "\n",
    "link2 = RevoluteDH(d=0, a=1.0, alpha=0, m=17.4, qlim=[-1.9, 1.9],\n",
    "                  r=np.array([-0.3638, 0.006, 0.2275]), Jm=200e-6,\n",
    "                  G=100, B=1.38e-3, I=[0.13, 0.524, 0.539, 0, 0, 0])\n",
    "\n",
    "link3 = RevoluteDH(d=0, a=1.0, alpha=0, m=4.8, qlim=[-2.4, 2.4],\n",
    "                  r=np.array([-0.0203, -0.0141, 0.070]), Jm=200e-6,\n",
    "                  G=50, B=1.38e-3,\n",
    "                  I=[0.066, 0.086, 0.0125, 0, 0, 0])\n",
    "\n",
    "my_bot = DHRobot([link1, link2, link3], name='3dof-manipulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some useful joint configurations and take a look at the parameters of our robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Link 0:: Revolute   theta=q1 + 0.00,  d= 1.00,  a= 0.00,  alpha= 1.57\n",
      "  m     =         0 \n",
      "  r     =         0        0        0 \n",
      "          |        0        0        0 | \n",
      "  I     = |        0     0.35        0 | \n",
      "          |        0        0        0 | \n",
      "  Jm    =    0.0002 \n",
      "  B     =    0.0014 \n",
      "  Tc    =         0(+)        0(-) \n",
      "  G     =        60 \n",
      "  qlim  =      -2.8 to      2.8\n",
      "\n",
      "Link 1:: Revolute   theta=q2 + 0.00,  d= 0.00,  a= 1.00,  alpha= 0.00\n",
      "  m     =        17 \n",
      "  r     =     -0.36    0.006     0.23 \n",
      "          |     0.13        0        0 | \n",
      "  I     = |        0     0.52        0 | \n",
      "          |        0        0     0.54 | \n",
      "  Jm    =    0.0002 \n",
      "  B     =    0.0014 \n",
      "  Tc    =         0(+)        0(-) \n",
      "  G     =     1e+02 \n",
      "  qlim  =      -1.9 to      1.9\n",
      "\n",
      "Link 2:: Revolute   theta=q3 + 0.00,  d= 0.00,  a= 1.00,  alpha= 0.00\n",
      "  m     =       4.8 \n",
      "  r     =     -0.02   -0.014     0.07 \n",
      "          |    0.066        0        0 | \n",
      "  I     = |        0    0.086        0 | \n",
      "          |        0        0    0.013 | \n",
      "  Jm    =    0.0002 \n",
      "  B     =    0.0014 \n",
      "  Tc    =         0(+)        0(-) \n",
      "  G     =        50 \n",
      "  qlim  =      -2.4 to      2.4\n"
     ]
    }
   ],
   "source": [
    "# Add some useful configurations\n",
    "my_bot.qz = np.array([0,0,0]) # zero angles\n",
    "my_bot.qr = np.array([0, np.pi/2, 0]) # ready pose, arm up\n",
    "my_bot.qs = np.array([0, 0, np.pi/2]) # straight and elbow up\n",
    "\n",
    "# Print the kinematic & dynamic parameters\n",
    "my_bot.printdyn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PD Controller\n",
    "\n",
    "How can we make our robot hold a desired configuration? Let's define a PD controller for each joint and use it to compute the required torque.\n",
    "\n",
    "To determine the proportional and derivative gains $K_p$ and $K_d$ for each joint we have added a helper function shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_pd_gains(my_bot, w=100.0):\n",
    "    \"\"\"\n",
    "    Compute proportional and derivative gains for each joint controller\n",
    "    :param my_bot (DHRobot): Robot for which gains will be computed\n",
    "    :param w (float): Base coefficient for the computation of the gains\n",
    "    :return tuple of np.arrays: Proportional and derivate gains for each joint in my_bot\n",
    "    \"\"\"\n",
    "    K_p = []\n",
    "    K_d = []\n",
    "    \n",
    "    for i in range(my_bot.n):\n",
    "        Kp_i = w * w * my_bot.links[i].Jm\n",
    "        Kd_i = 2 * w * my_bot.links[i].Jm - my_bot.links[i].B\n",
    "        \n",
    "        K_p.append(Kp_i)\n",
    "        K_d.append(Kd_i)\n",
    "\n",
    "    return np.array(K_p), np.array(K_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define our PD Controller\n",
    "\n",
    "This code is based on our PID implementation from Week 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PD(object):\n",
    "    \n",
    "    \"\"\"A simple PD controller.\"\"\"\n",
    "\n",
    "    def __init__(self, desired_state=None, K_p=None, \n",
    "                 K_d=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize a new PD controller.\n",
    "        :param desired_q: Desired robot states (q, dq)\n",
    "        :param K_p: The value for the proportional gain K_p\n",
    "        :param K_d: The value for the derivative gain K_d\n",
    "        \"\"\"        \n",
    "        if desired_state is None:\n",
    "            desired_state = np.zeros(self.system.n)\n",
    "            \n",
    "        if K_p is None:\n",
    "            K_p = np.ones(self.system.n) * 10\n",
    "                        \n",
    "        if K_d is None:\n",
    "            K_d = np.ones(self.system.n) * 0.5\n",
    "        \n",
    "        self.set_point = desired_state\n",
    "        self.K_p = K_p\n",
    "        self.K_d = K_d\n",
    "                \n",
    "    \n",
    "    def __compute_error__(self, system):\n",
    "        \"\"\"\n",
    "        This method computes error between the robot's current and desired states\n",
    "        :param system (DHRobot): Robot to control\n",
    "        :return 1xn float array: joint and velocity error\n",
    "        \"\"\"\n",
    "        return self.set_point - np.r_[system.q, system.qd]\n",
    "    \n",
    "    \n",
    "    def compute_control(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        This method computes the next control signal u_t so as to reduce the error\n",
    "        between the robot's current state and the desired state (self.set_point)\n",
    "        :param system (DHRobot): Robot to control\n",
    "        :return 1xn float array: Torque input to apply to robot\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute error\n",
    "        error_t = self.__compute_error__(system)\n",
    "        \n",
    "        # Compute new control\n",
    "        new_control = self.K_p * error_t[:system.n] + self.K_d * error_t[system.n:]\n",
    "                            \n",
    "        return new_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Run and Apply Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bee250ba36ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Compute acceleration using forward dynamics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mnew_qdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_bot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_bot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_bot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Compute new states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brand\\documents\\bj\\education\\2020 phdeng (monash)\\2020-s2 intelligent robotics\\github\\ece4078_practicals\\week10\\support\\robotics-toolbox-python\\roboticstoolbox\\robot\\Dynamics.py\u001b[0m in \u001b[0;36maccel\u001b[1;34m(self, q, qd, torque)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mqddI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqdI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqddI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrav\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;31m# Compute gravity and coriolis torque torques resulting from zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brand\\documents\\bj\\education\\2020 phdeng (monash)\\2020-s2 intelligent robotics\\github\\ece4078_practicals\\week10\\support\\robotics-toolbox-python\\roboticstoolbox\\robot\\DHRobot.py\u001b[0m in \u001b[0;36mwrapper_check_rne\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rne_ob\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rne_changed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete_rne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m                 \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_rne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rne_changed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brand\\documents\\bj\\education\\2020 phdeng (monash)\\2020-s2 intelligent robotics\\github\\ece4078_practicals\\week10\\support\\robotics-toolbox-python\\roboticstoolbox\\robot\\DHRobot.py\u001b[0m in \u001b[0;36m_init_rne\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m24\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rne_ob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmdh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgravity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_rne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# Define desired state. We want the robot to be on the ready state, arm up with zero velocity\n",
    "desired_state = np.r_[my_bot.qr, np.zeros(my_bot.n)]\n",
    "\n",
    "# Set robot's initial state\n",
    "my_bot.q = my_bot.qz\n",
    "my_bot.qd = np.zeros((1,my_bot.n))\n",
    "my_bot.qdd = np.zeros((1,my_bot.n))\n",
    "\n",
    "# Define time step\n",
    "dt = 0.05\n",
    "\n",
    "# Compute gain\n",
    "K_p, K_d = define_pd_gains(my_bot, w=100)\n",
    "\n",
    "# Create a PD controller\n",
    "pd_control = PD(desired_state=desired_state, K_p=K_p, K_d=K_d)\n",
    "\n",
    "# Variables needed for plotting\n",
    "robot_state = {'q': [], 'qd': []}\n",
    "\n",
    "# Number of iterations for control loop\n",
    "max_iterations = 200\n",
    "\n",
    "# Control loop\n",
    "for i in range(max_iterations):\n",
    "        \n",
    "    # Call controller to get new torque signal\n",
    "    tau = pd_control.compute_control(my_bot)\n",
    "    \n",
    "    # Compute acceleration using forward dynamics\n",
    "    new_qdd = my_bot.accel(my_bot.q, my_bot.qd, tau)\n",
    "    \n",
    "    # Compute new states\n",
    "    new_qd = my_bot.qd + new_qdd * dt\n",
    "    new_q = my_bot.q + new_qd * dt\n",
    "       \n",
    "    # Assign new state to robot\n",
    "    my_bot.q = new_q\n",
    "    my_bot.qd = new_qd\n",
    "    my_bot.qdd = new_qdd\n",
    "    \n",
    "    # Keep track of variable for plotting\n",
    "    robot_state[\"q\"].append(my_bot.q)\n",
    "    robot_state[\"qd\"].append(my_bot.qd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Plot Robot's Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtb.tools.trajectory.qplot(np.array(robot_state[\"q\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Observe Robot's Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization context\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim3d(-2.0, 2.0)\n",
    "ax.set_ylim3d(-2.0, 2.0)\n",
    "ax.set_zlim3d(0.0, 3.0)\n",
    "ax.set_xlabel(r'$x_0$', fontsize=12)\n",
    "ax.set_ylabel(r'$y_0$', fontsize=12)\n",
    "ax.set_zlabel(r'$z_0$', fontsize=12)\n",
    "\n",
    "# Create visualizer instance\n",
    "my_plot = RobotJupyterPlot(my_bot, ax, readonly=True)\n",
    "\n",
    "# Get trajectory to plot\n",
    "path_to_plot = np.array(robot_state[\"q\"])\n",
    "\n",
    "def init():\n",
    "    my_plot.draw()\n",
    "    return\n",
    "\n",
    "def animate(i):\n",
    "    if i < len(path_to_plot):\n",
    "        my_bot.q = path_to_plot[i]\n",
    "        my_plot.draw()\n",
    "    return\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, animate, frames=len(path_to_plot), blit=False, interval=100, init_func=init,\n",
    "                              repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gravity Compensation and Feedback Linearisation\n",
    "\n",
    "Even with our PD controller, the tracking performance is not perfect, and it's hard to find the optimal PD gains. How can we improve our control algorithm?\n",
    "\n",
    "Two possible improvements can be added:\n",
    "1. Add the gravity component of torque to the output of our PD controller\n",
    "2. Combine our PD controller with feedback linearisation and compute the required torque input for each time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Gravity Compensation\n",
    "\n",
    "To add gravity compensation we will use the function ``grav_bot.gravload()``. This function calculates the joint gravity loading of the robot in the current joint configuration.\n",
    "\n",
    "**TODO**: Extend the torque computation step (line 27) to include the torques due to gravity\n",
    "\n",
    "**Interact**: \n",
    "- Test our new controller with different desired states. Here is an example of how to define a new desired state\n",
    "```python\n",
    "desired_state = np.r_[np.array([np.pi/2, 0, -np.pi/2]), np.zeros(grav_bot.n)]\n",
    "```\n",
    "- Observe what happens when the gains $K_p$ and $K_p$ change. Here is an example of how to manually define these gains\n",
    "```python\n",
    "K_p=[1.0, 1.0, 1.0]\n",
    "K_d=[0.01, 0.01, 0.01]\n",
    "```\n",
    "If the gains are set manually, do not forget to comment out line 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of our robot and define useful states\n",
    "grav_bot = my_bot.copy()\n",
    "grav_bot.qz = np.array([0,0,0]) # zero angles\n",
    "grav_bot.qr = np.array([0, np.pi/2, 0]) # ready pose, arm up\n",
    "grav_bot.qs = np.array([0, 0, np.pi/2]) # straight and elbow up\n",
    "\n",
    "# Define desired state. We want the robot to be on the ready state, arm up with zero velocity\n",
    "desired_state = np.r_[grav_bot.qr, np.zeros(grav_bot.n)]\n",
    "\n",
    "# Set initial robot state\n",
    "grav_bot.q = grav_bot.qz\n",
    "grav_bot.qd = np.zeros((1,grav_bot.n))\n",
    "grav_bot.qdd = np.zeros((1,grav_bot.n))\n",
    "\n",
    "# Define time step\n",
    "dt = 0.05\n",
    "\n",
    "# Compute gain\n",
    "K_p, K_d = define_pd_gains(grav_bot, w=100)\n",
    "\n",
    "# Create a PID controller\n",
    "pd_control = PD(desired_state=desired_state, K_p=K_p, K_d=K_d)\n",
    "\n",
    "# Variables needed for plotting\n",
    "grav_robot_state = {'q': [], 'qd': []}\n",
    "\n",
    "# Number of iterations control loop\n",
    "max_iterations = 400\n",
    "\n",
    "# This is our control loop\n",
    "for i in range(max_iterations):\n",
    "        \n",
    "    #TODO: Combine PD controller and gravity compensation torque outputs\n",
    "    tau = pd_control.compute_control(grav_bot) + grav_bot.gravload()\n",
    "    \n",
    "    # Compute acceleration\n",
    "    new_qdd = grav_bot.accel(grav_bot.q, grav_bot.qd, tau)\n",
    "    \n",
    "    # Compute new states\n",
    "    new_qd = grav_bot.qd + new_qdd * dt\n",
    "    new_q = grav_bot.q + new_qd * dt\n",
    "    \n",
    "    # Assign new state to robot\n",
    "    grav_bot.q = new_q\n",
    "    grav_bot.qd = new_qd\n",
    "    grav_bot.qdd = new_qdd\n",
    "    \n",
    "    grav_robot_state[\"q\"].append(grav_bot.q)\n",
    "    grav_robot_state[\"qd\"].append(grav_bot.qd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Plot Robot's Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtb.tools.trajectory.qplot(np.array(grav_robot_state[\"q\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Observe Robot's Behaviour\n",
    "\n",
    "Does our robot reach the desired state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization context\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim3d(-2.0, 2.0)\n",
    "ax.set_ylim3d(-2.0, 2.0)\n",
    "ax.set_zlim3d(0.0, 3.0)\n",
    "ax.set_xlabel(r'$x_0$', fontsize=12)\n",
    "ax.set_ylabel(r'$y_0$', fontsize=12)\n",
    "ax.set_zlabel(r'$z_0$', fontsize=12)\n",
    "\n",
    "# Set bot back to initial state\n",
    "grav_bot.q = grav_bot.qz\n",
    "# Create visualizer instance\n",
    "my_plot = RobotJupyterPlot(grav_bot, ax, readonly=True)\n",
    "\n",
    "# Get trajectory to plot\n",
    "path_to_plot = np.array(grav_robot_state[\"q\"])\n",
    "\n",
    "def init():\n",
    "    my_plot.draw()\n",
    "    return\n",
    "\n",
    "def animate(i):\n",
    "    if i < len(path_to_plot):\n",
    "        grav_bot.q = path_to_plot[i]\n",
    "        my_plot.draw()\n",
    "    return\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, animate, frames=len(path_to_plot), blit=False, interval=100, init_func=init,\n",
    "                              repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feedback Linearisation\n",
    "\n",
    "To add feedback linearisation we will:\n",
    "1. Use our PD controller to compute the desired acceleration\n",
    "2. Use inverse dynamics (i.e.,  function ``feed_bot.rne(q, qd, qdd)``) to calculate the joint torques required for the robot to achieve a desired configuration $[q, qd, qdd]$, with $qdd$ being the desired acceleration\n",
    "\n",
    "**TODO**: Given the desired acceleration ``d_acc``, use inverse dynamics to compute the required torque input (line 32)\n",
    "\n",
    "**Interact**: \n",
    "- Test our new controller with different desired states. Here is an example of how to define a new desired state\n",
    "```python\n",
    "desired_state = np.r_[np.array([np.pi/2, 0, -np.pi/2]), np.zeros(feed_bot.n)]\n",
    "```\n",
    "- Observe what happens when the gains $K_p$ and $K_p$ change. Here is an example of how to manually define these gains\n",
    "```python\n",
    "K_p=[1.0, 1.0, 1.0]\n",
    "K_d=[0.01, 0.01, 0.01]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of our robot and define useful states\n",
    "feed_bot = my_bot.copy()\n",
    "feed_bot.qz = np.array([0,0,0]) # zero angles\n",
    "feed_bot.qr = np.array([0, np.pi/2, 0]) # ready pose, arm up\n",
    "feed_bot.qs = np.array([0, 0, np.pi/2]) # straight and elbow up\n",
    "\n",
    "# Define desired state. We want the robot to be on the ready state, arm up with zero velocity\n",
    "desired_state = np.r_[feed_bot.qr, np.zeros(feed_bot.n)]\n",
    "\n",
    "# Set initial robot state\n",
    "feed_bot.q = feed_bot.qz\n",
    "feed_bot.qd = np.zeros((1,feed_bot.n))\n",
    "feed_bot.qdd = np.zeros((1,feed_bot.n))\n",
    "\n",
    "# Define time step\n",
    "dt = 0.05\n",
    "\n",
    "# Define the proportional and derivative gains\n",
    "K_p = [2., 2., 2.]\n",
    "K_d = [10.,25.,25.]\n",
    "\n",
    "# Create a PD controller\n",
    "pd_control = PD(desired_state=desired_state, K_p=K_p, K_d=K_d)\n",
    "\n",
    "# Variables needed for plotting\n",
    "feed_robot_state = {'q': [], 'qd': [], 'tau': []}\n",
    "\n",
    "# Number of iterations in control loop\n",
    "max_iterations = 2000\n",
    "\n",
    "# This is our control loop\n",
    "for i in range(max_iterations):\n",
    "        \n",
    "    # Compute desired acceleration\n",
    "    d_acc = pd_control.compute_control(feed_bot)\n",
    "    \n",
    "    # TODO: Use inverse dynamics to compute new torque input\n",
    "    tau = feed_bot.rne(feed_bot.q, feed_bot.qd, d_acc)\n",
    "    \n",
    "    # Apply forward dynamics\n",
    "    new_qdd = feed_bot.accel(feed_bot.q, feed_bot.qd, tau)\n",
    "    \n",
    "    # Compute new states\n",
    "    new_qd = feed_bot.qd + new_qdd * dt\n",
    "    new_q = feed_bot.q + new_qd * dt\n",
    "\n",
    "    # Assign new state to robot\n",
    "    feed_bot.q = new_q\n",
    "    feed_bot.qd = new_qd\n",
    "    feed_bot.qdd = new_qdd\n",
    "   \n",
    "    # Keep track of results for plotting\n",
    "    feed_robot_state[\"q\"].append(feed_bot.q)\n",
    "    feed_robot_state[\"qd\"].append(feed_bot.qd)\n",
    "    feed_robot_state[\"tau\"].append(tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Plot Robot's Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtb.tools.trajectory.qplot(np.array(feed_robot_state[\"q\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Observe Robot's Behaviour\n",
    "\n",
    "Does our robot reach the desired state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization context\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim3d(-2.0, 2.0)\n",
    "ax.set_ylim3d(-2.0, 2.0)\n",
    "ax.set_zlim3d(0.0, 3.0)\n",
    "ax.set_xlabel(r'$x_0$', fontsize=12)\n",
    "ax.set_ylabel(r'$y_0$', fontsize=12)\n",
    "ax.set_zlabel(r'$z_0$', fontsize=12)\n",
    "\n",
    "# Set robot back to initial state\n",
    "feed_bot.q = feed_bot.qz\n",
    "# Create visualizer instance\n",
    "my_plot = RobotJupyterPlot(feed_bot, ax, readonly=True)\n",
    "\n",
    "# Get trajectory to plot\n",
    "path_to_plot = np.array(feed_robot_state[\"q\"])\n",
    "\n",
    "def init():\n",
    "    my_plot.draw()\n",
    "    return\n",
    "\n",
    "def animate(i):\n",
    "    if i < len(path_to_plot):\n",
    "        feed_bot.q = path_to_plot[i]\n",
    "        my_plot.draw()\n",
    "    return\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, animate, frames=len(path_to_plot), blit=False, interval=100, init_func=init,\n",
    "                              repeat=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
